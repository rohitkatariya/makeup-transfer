{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greenhouse-repository",
   "metadata": {},
   "source": [
    "# Digital Makeup Transfer\n",
    "Digital Makeup Transfer based on paper by Dong Guo and Terence Sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-desire",
   "metadata": {},
   "source": [
    "### Procedure Followed:\n",
    "- Landmark creation\n",
    "  - Facial landmark detection\n",
    "      - We used a python library function dlib to denote the pixel locations of 81 control points of the face which cover all the face control points. These include eyebrows, eyes, nose, lips and boundary of face. \n",
    "  - Landmark point division\n",
    "      - Here we segmented the landmark points to assign them the region that they represent. <br>\n",
    "      <img src=\"data/files_for_md/landmarks.jpg\" width = 300>  <br>\n",
    "  - Create image masks using convex hull\n",
    "      - We do this to display the different regions of the image.\n",
    "  \n",
    "  <img src=\"data/files_for_md/mask_frame.jpg\" width = 300>  <br>\n",
    "  - We then divide these regions into diffrent sets:\n",
    "      - C1 - Skin, eyebrows,nose [we call this \"others\" region]<br>\n",
    "      <img src=\"data/files_for_md/region_mask_0.jpg\" width = 300> <img src=\"data/files_for_md/region_frame_0.jpg\" width = 300>  <br>\n",
    "      - C2 lips <br>\n",
    "      <img src=\"data/files_for_md/region_mask_1.jpg\" width = 300> <img src=\"data/files_for_md/region_frame_1.jpg\" width = 300><br>\n",
    "      - C3 eyes, mouth cavity <br>\n",
    "      <img src=\"data/files_for_md/region_mask_2.jpg\" width = 300> <img src=\"data/files_for_md/region_frame_2.jpg\" width = 300><br>\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-pointer",
   "metadata": {},
   "source": [
    "- Triangulation / mesh creation\n",
    "  - Compute triangles using cv2.Subdiv2D\n",
    "  - Convert triangle points to landmark indices so that this mesh can be universally used in different images\n",
    "  \n",
    "  <img src=\"data/files_for_md/mesh_image.jpg\" width = 300> <img src=\"data/files_for_md/eg_mesh_image.jpg\" width = 300>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-christian",
   "metadata": {},
   "source": [
    "- Assign every triangle the region it belongs to.\n",
    "  - Each category is further divided into 3 regions on which different transfer method is to be used.\n",
    "  - Apply affine transformation to resize and reorient corresponding triangles to get a warped image. \n",
    "  - Combining different triangles to get the transformed image.\n",
    "      - created masks for combining different triangles. Here we faced a lot of issues because a lot of mesh lines were showing up. So we developed an innovative way to mask away the common boundary that was getting added multiple times when it is shared among different triangles.<br>\n",
    "      Image after Afine Transfer:<br>\n",
    "      <img src=\"data/files_for_md/transfered_image.jpg\" width = 300>  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-february",
   "metadata": {},
   "source": [
    " - Applying Transfers\n",
    "      - We divided the image into 3 regions: \n",
    "          - C1 - Skin, eyebrows,nose [we call this \"others\" region]\n",
    "          - C2 lips \n",
    "          - C3 eyes, mouth cavity \n",
    "      - We apply different transfers to different regions\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-proceeding",
   "metadata": {},
   "source": [
    "# C1 Region\n",
    "- Skin transfer\n",
    "  - Here we divide the images into 3 layer components.\n",
    "  - we first convert to LAB color space\n",
    "  - Detail layer, structure layer, color layer\n",
    "## Structure layer\n",
    "- structure layer is obtained by applying Bilateral filtering\n",
    "  - Highlight transfer: here we get try getting gradient with laplacian and sobel operators and we try to add it to smoothened structure layer. \n",
    "  <figure>\n",
    "    <img src=\"data/files_for_md/dest_structure_layer.jpg\" width = 300>  \n",
    "    <figcaption>Structure Layer</figcaption>\n",
    "    </figure> \n",
    "\n",
    "## Detail layer\n",
    "- Detail layer is got by subtracting structure layer from lightness component\n",
    "  - Skin detail transfer - here we use a weighted sum of detailed layer from both example and the subject image\n",
    "  <figure>\n",
    "<img src=\"data/files_for_md/dest_detail_layer.jpg\" width = 300>  \n",
    "<figcaption>Detail Layer</figcaption>\n",
    "</figure> \n",
    "\n",
    "## Color layer\n",
    "- Color layer is the a,b component of LAB layer\n",
    "  - Color transfer - where we apply alpha blending of color layers.\n",
    "<figure>\n",
    "<img src=\"data/files_for_md/dest_0color_layer.jpg\" width = 300>  \n",
    "<figcaption>Color Layer</figcaption>\n",
    "</figure> \n",
    "<figure>\n",
    "<img src=\"data/files_for_md/dest_1color_layer.jpg\" width = 300>  \n",
    "<figcaption>Color Layer</figcaption>\n",
    "</figure> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-confidence",
   "metadata": {},
   "source": [
    "- Lip tansfers\n",
    "  - Here we convert the image into LAB color space.\n",
    "  - we apply histogram equaliztion to both subject and example image.\n",
    "  - Now for every point p in the subject image's lip region we find the closest lip point in the transfered image using the following similarity function\n",
    "      {G(|q−p|)G(|E(q)− I(p)|)} where G is the gaussian function.\n",
    "  - once we get the closest point we copy the color and lightness values to the result image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-determination",
   "metadata": {},
   "source": [
    "- in the eyes mouth cavity and background region no transfers are applied and we use these as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-throat",
   "metadata": {},
   "source": [
    "Lips, color, skin detail transfer:<br>\n",
    "<img src=\"data/files_for_md/combined_layer.jpg\" width=300>  \n",
    "Lips, color, skin detail, highlights transfer:<br>\n",
    "<img src=\"data/files_for_md/highlights.jpg\" width=300>      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-orlando",
   "metadata": {},
   "source": [
    "# Effect of highlight effect\n",
    "\n",
    "Highlight effect can be better viewed in the following image(leftmost: example image; middle: without highlight transfer; rightmost: with highlights transfer ) \n",
    "\n",
    "Here we observe the effect of lighting on both ends of the cheeks where we see that highlights transfer capture the shaddow and gradient changes much better. <br>\n",
    "<img src=\"data/files_for_md/highlight_effect.png\" width=1200>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-medicaid",
   "metadata": {},
   "source": [
    "# Other Examples\n",
    "\n",
    "Destination image; Transferred image \n",
    "\n",
    "<img src=\"data/files_for_md/h.jpg\" width=500>  <img src=\"data/files_for_md/h_combined_layer.jpg\" width=500> \n",
    "\n",
    "<img src=\"data/files_for_md/m.jpg\" width=500>  <img src=\"data/files_for_md/m_combined_layer.jpg\" width=500> \n",
    "\n",
    "<img src=\"data/files_for_md/eyes.jpg\" width=500>  <img src=\"data/files_for_md/eyes_combined_layer.jpg\" width=500> \n",
    "<img src=\"data/files_for_md/man.jpg\" width=500>  <img src=\"data/files_for_md/man_combined_layer.jpg\" width=500> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-target",
   "metadata": {},
   "source": [
    "#  X-DOG \n",
    "- In this part we apply xdog with different thresholds to get multiple images. \n",
    "- Once we get this stylized image, we input this into above pipeline to get makeup transfer on this image.  \n",
    "\n",
    "<img src=\"data/files_for_md/xdog_combined_layer.jpg\" width = 600>              \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-solomon",
   "metadata": {},
   "source": [
    "# References\n",
    "- Digital Makeup Transfer based on paper by Dong Guo and Terence Sim\n",
    "- dlib predictor downloaded from https://github.com/codeniko/shape_predictor_81_face_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-blake",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
